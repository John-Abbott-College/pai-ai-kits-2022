# Principles for Ethical AI

## Ethical Principles

While there is no universal set of guidelines or regulations governing AI ethics, a consensus is beginning to emerge around the importance of the following principles: **responsibility, fairness, transparency, and freedom** (Jobin et al., 2019).&#x20;

<table><thead><tr><th width="173">Principle</th><th>Description</th></tr></thead><tbody><tr><td>Responsibility</td><td><ul><li>encompasses the accountability and conscientiousness required from individuals and organizations involved in the development, deployment, and use of artificial intelligence systems </li></ul></td></tr><tr><td>Fairness</td><td><ul><li>encompasses the pursuit of equitable and impartial treatment of individuals and groups throughout the development, deployment, and utilization of AI systems</li></ul></td></tr><tr><td>Transparency</td><td><ul><li>refers to the degree to which AI systems' inner workings, decision-making processes, and underlying data are open, understandable, and accessible to users, stakeholders, and the general public</li></ul></td></tr><tr><td>Freedom</td><td><ul><li>refers to the protection and preservation of individual autonomy, privacy, and agency in the face of AI systems</li><li>involves ensuring that AI technologies do not unduly limit or infringe upon the fundamental rights and freedoms of individuals</li></ul></td></tr></tbody></table>

<details>

<summary>Learn More</summary>



With the growing prevalence of AI in various domains, it is of utmost importance to eliminate biases associated with gender, race, ethnicity, and other sensitive factors ([Ref](https://www.csa.iisc.ac.in/fate.htm)). To tackle this issue, a range of ethical principles has been formulated to offer guidance for the development and deployment of AI systems, with the objective of fostering fairness and preventing discrimination (Jobin et al., 2019). While there is no universal set of guidelines or regulations governing AI ethics, a consensus is beginning to emerge around the importance of the following principles: responsibility, fairness, transparency, and freedom (Jobin et al., 2019). &#x20;

&#x20;

Responsibility &#x20;

* Responsibility as a principle of AI ethics encompasses the accountability and conscientiousness required from individuals and organizations involved in the development, deployment, and use of artificial intelligence systems. It means recognizing and accepting responsibility for the actions and consequences arising from the use of AI systems. This involves being answerable for the decisions made, the data used, and the outcomes produced by AI technologies.&#x20;
* There is ongoing debate surrounding ethical principles in AI due to the absence of definitive guidelines, with particular emphasis on the contentious issue of assigning responsibility for the outcomes of AI. &#x20;
* Various stakeholders have been identified as responsible and liable for the actions and choices of AI, including AI developers, designers, institutions, and the industry (Jobin et al., 2019). Additionally, there is disagreement regarding whether AI should be held accountable in a manner resembling human accountability, or if humans should always bear the ultimate responsibility for technological artifacts (Jobin et al., 2019). &#x20;

Fairness &#x20;

* Fairness encompasses the pursuit of equitable and impartial treatment of individuals and groups throughout the development, deployment, and utilization of AI systems. &#x20;
* To accomplish this, it is crucial to address biases inherent in both the data employed for training AI systems and the systems themselves. &#x20;
* By mitigating these biases, it is possible to prevent AI applications from yielding unjust or discriminatory consequences that hinge on factors like race, gender, ethnicity, or socioeconomic status.&#x20;

Transparency &#x20;

* Transparency, in the context of AI ethics, refers to the degree to which AI systems' inner workings, decision-making processes, and underlying data are open, understandable, and accessible to users, stakeholders, and the general public. &#x20;
* It involves ensuring that AI systems are not overly opaque or "black-boxed," but instead promote clarity and accountability by providing explanations, justifications, and insights into how they operate, how they arrive at decisions, and how they handle and process data. &#x20;
* Efforts to enhance transparency involve endeavors aimed at improving explainability, auditability, or other forms of communication and disclosure (Jobin et al., 2019) &#x20;
* Explainability pertains to the assurance that decisions made by AI systems, along with the data influencing those decisions, can be clarified to end-users and other relevant parties using language that is not overly technical. (Fat/ML) &#x20;
* Auditability encompasses the provision of opportunities for external third parties to comprehensively understand, thoroughly investigate, and critically assess AI systems. Auditability can be supported through permissive terms of use, detailed documentation, and disclosure of information that enables monitoring, checking, and criticism. (Fat/ML) &#x20;

Freedom &#x20;

* Freedom refers to the protection and preservation of individual autonomy, privacy, and agency in the face of AI systems. It involves ensuring that AI technologies do not unduly limit or infringe upon the fundamental rights and freedoms of individuals.&#x20;
* Individuals must have:&#x20;
* Ability to make informed choices&#x20;
* Control over their personal data&#x20;
* Protection against unwarranted surveillance&#x20;
* Protection against manipulation by AI systems&#x20;

</details>

## Applying the Principles

There are several approaches researchers are taking to mitigate or minimize bias in AI systems, such as: &#x20;

* utilizing feedback and learning from errors by testing AI systems with a diverse range of individuals ([Ref](https://docs.google.com/document/d/1i\_\_XQcSVF1BfHCFWRZ3GkLaqWde0RVxyz2o85xBMMJw/edit))
* ensuring a balance in the training data employed to develop AI models ([Ref](https://docs.google.com/document/d/1i\_\_XQcSVF1BfHCFWRZ3GkLaqWde0RVxyz2o85xBMMJw/edit))&#x20;
* developing novel methods to detect and identify biases in AI systems ([Ref](https://docs.google.com/document/d/1i\_\_XQcSVF1BfHCFWRZ3GkLaqWde0RVxyz2o85xBMMJw/edit))
* establishing open datasets and fostering collaborations through partnerships ([Ref](https://docs.google.com/document/d/1i\_\_XQcSVF1BfHCFWRZ3GkLaqWde0RVxyz2o85xBMMJw/edit))

<details>

<summary>Learn More</summary>

By acknowledging the potential biases and ethical considerations associated with AI, we can strive to develop AI systems that are fair, accountable, and uphold ethical standards, while promoting inclusivity. However, achieving these goals can be challenging due to the complexity of AI systems, which often involve numerous variables that make comprehensive understanding difficult. &#x20;

It is important to note that there is no one set of rules that have been agreed upon to guide the development and deployment of ethical AI. Ethical questions in AI are still subject to ongoing debates and discussions that are expected to persist for years to come (Borenstein et al., 2021). Despite these challenges, it is essential to make continuous efforts in creating more ethical AI systems.

</details>
