# Bias in AI

### Defining Bias

> “Bias is a prejudice for or against something or somebody, that may result in unfair decisions.” (European Commission, 2018)

### Uncovering Bias in AI

_Gender Shades_, a groundbreaking study conducted by MIT researcher Joy Buolamwini, uncovered bias in facial recognition algorithms.

Watch the below _Gender Shades_ video.&#x20;

{% embed url="https://www.youtube.com/watch?embeds_referring_euri=http://gendershades.org/&feature=emb_logo&source_ve_path=Mjg2NjY&v=TWWsW1w-BVo" %}

<details>

<summary>Learn More - 1. Bias in AI  &#x26;  2. Issues with Facial Recognition Systems</summary>

### 1. **Bias in AI**&#x20;

Humans are known to exhibit bias in their decisions, and since AI systems are created by humans, there is a possibility of unintentionally injecting bias into them (European Commission, 2018). This is especially true in AI systems that rely on machine learning techniques and the collection and selection of training data (European Commission, 2018).&#x20;

If the training data is not diverse and balanced, the system may learn to make unfair decisions (European Commission, 2018). When AI systems are applied to scenarios involving people, biases related to shapes, colors, skin color, or gender can arise ([Ref](https://www.digitaltechnologieshub.edu.au/teach-and-assess/classroom-resources/lesson-ideas/data-bias-in-ai/)). &#x20;

These biases present ethical concerns as AI systems can reinforce and amplify existing biases, and their decision-making process may be difficult to understand or question due to their complex nature (Shaw, 2019). Despite the superior processing capabilities of AI, it cannot be assumed to always be fair and unbiased since it is created by fallible humans prone to bias and judgment (Bossman, 2016).&#x20;

### **2. Facial Recognition Systems**&#x20;

Commonly used facial recognition systems have been shown to over-represent certain populations, leading to better performance for them while neglecting others ([Ref](https://docs.google.com/document/d/1i\_\_XQcSVF1BfHCFWRZ3GkLaqWde0RVxyz2o85xBMMJw/edit)). This imbalance in training data, known as "selection bias," particularly affects dark-skinned women ([Ref](https://docs.google.com/document/d/1i\_\_XQcSVF1BfHCFWRZ3GkLaqWde0RVxyz2o85xBMMJw/edit)).&#x20;

Unfortunately, little progress has been made in accurately recognizing facial features of black women since Buolamwini's investigation in 2015 (Babusi, 2020). Recent studies have shown that general application facial recognition systems in the US misidentify people of color at significantly higher rates than white individuals (Babusi, 2020). &#x20;

</details>
